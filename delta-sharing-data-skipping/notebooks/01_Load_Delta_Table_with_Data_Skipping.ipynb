{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72b5f35d",
   "metadata": {},
   "source": [
    "### Data Skipping and Z-Ordering\n",
    " With the release of Data Skipping in Delta Lake 1.2.0, column-level statistics like min/max are now available. Statistics are saved in the Delta Lake transaction log (DeltaLog) every time an `add` action is performed corresponding to adding a new Parquet file.\n",
    " By leveraging min-max ranges, Delta Lake is able to skip the Parquet files that are out of the range of the querying field values (Data Skipping). In order to make it effective, data can be clustered by Z-Order columns so that min-max ranges are narrow and, ideally, non-overlapping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd168839",
   "metadata": {},
   "source": [
    "### Delta Table Structure\n",
    "\n",
    " You are wroking at a cyber security company. Your team collects traffic data which is created by an open source\n",
    "network traffic analyzer. The schema is straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec1ecdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/29 02:12:21 WARN Utils: Your hostname, aix.local resolves to a loopback address: 127.0.0.1; using 192.168.2.100 instead (on interface en0)\n",
      "23/04/29 02:12:21 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      ":: loading settings :: url = jar:file:/Users/shin/.local/share/virtualenvs/sharing-examples-hEeTnWv9/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/shin/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/shin/.ivy2/jars\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-f713cd56-1550-4f2f-9996-300b9488e7e4;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-core_2.12;2.2.0 in central\n",
      "\tfound io.delta#delta-storage;2.2.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.8 in central\n",
      ":: resolution report :: resolve 284ms :: artifacts dl 11ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-core_2.12;2.2.0 from central in [default]\n",
      "\tio.delta#delta-storage;2.2.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.8 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-f713cd56-1550-4f2f-9996-300b9488e7e4\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/9ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/29 02:12:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/29 02:12:24 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "+--------------+--------+---------------+--------+\n",
      "|src_ip        |src_port|dst_ip         |dst_port|\n",
      "+--------------+--------+---------------+--------+\n",
      "|236.71.116.143|32494   |245.119.140.199|12338   |\n",
      "|218.85.253.101|49762   |49.104.143.5   |18315   |\n",
      "|248.103.35.69 |48259   |216.87.133.237 |12454   |\n",
      "|163.88.107.182|46859   |100.82.126.51  |62569   |\n",
      "|145.139.254.71|17573   |245.142.160.215|15920   |\n",
      "+--------------+--------+---------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from delta import configure_spark_with_delta_pip\n",
    "\n",
    "\n",
    "builder = SparkSession.builder.appName('CreateDeltaTables') \\\n",
    "    .config(\n",
    "        'spark.jars.packages',\n",
    "        'io.delta:delta-core_2.12:2.2.0') \\\n",
    "    .config(\n",
    "        'spark.sql.extensions',\n",
    "        'io.delta.sql.DeltaSparkSessionExtension') \\\n",
    "    .config(\n",
    "        'spark.sql.catalog.spark_catalog',\n",
    "        'org.apache.spark.sql.delta.catalog.DeltaCatalog')\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "security = spark.read \\\n",
    "    .format('csv') \\\n",
    "    .option('header', 'true') \\\n",
    "    .option('inferSchema', 'true') \\\n",
    "    .load('../../data/security.csv')\n",
    "security.show(n=5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958d1d73",
   "metadata": {},
   "source": [
    "The structure of the table is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c45c604d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m../../data/security-table\u001b[0m\n",
      "├── \u001b[00m.part-00000-0825fe82-4459-49fb-b69b-4ded01674f63-c000.snappy.parquet.crc\u001b[0m\n",
      "├── \u001b[00m.part-00000-2c886aa1-d13a-4f54-8bd4-0ac291ab5e9a-c000.snappy.parquet.crc\u001b[0m\n",
      "├── \u001b[00m.part-00000-4aa0ba55-e6da-47d5-b256-dcdd2cbcd534-c000.snappy.parquet.crc\u001b[0m\n",
      "├── \u001b[00m.part-00000-65d0b700-60cf-403c-b69f-20a654d1f74f-c000.snappy.parquet.crc\u001b[0m\n",
      "├── \u001b[00m.part-00000-9e9fc6eb-a907-43db-8eda-d7ca94f825b8-c000.snappy.parquet.crc\u001b[0m\n",
      "├── \u001b[00m.part-00000-a5c1f6e4-3317-4a57-8287-af4b12f5e060-c000.snappy.parquet.crc\u001b[0m\n",
      "├── \u001b[00m.part-00000-ae3df0d8-d90d-44af-8f26-7a4f209d5df9-c000.snappy.parquet.crc\u001b[0m\n",
      "├── \u001b[00m.part-00000-bc507886-54ca-4e60-b0ac-6ef0103fee94-c000.snappy.parquet.crc\u001b[0m\n",
      "├── \u001b[00m.part-00000-c71f7f2e-05df-4386-a30a-9a154e2d6005-c000.snappy.parquet.crc\u001b[0m\n",
      "├── \u001b[00m.part-00000-eb12aca8-4707-4b2f-bfdd-1e36d3d7d324-c000.snappy.parquet.crc\u001b[0m\n",
      "├── \u001b[01;34m_delta_log\u001b[0m\n",
      "│   ├── \u001b[00m.00000000000000000000.json.crc\u001b[0m\n",
      "│   ├── \u001b[00m.00000000000000000001.json.crc\u001b[0m\n",
      "│   ├── \u001b[00m.00000000000000000002.json.crc\u001b[0m\n",
      "│   ├── \u001b[00m.00000000000000000003.json.crc\u001b[0m\n",
      "│   ├── \u001b[00m.00000000000000000004.json.crc\u001b[0m\n",
      "│   ├── \u001b[00m.00000000000000000005.json.crc\u001b[0m\n",
      "│   ├── \u001b[00m.00000000000000000006.json.crc\u001b[0m\n",
      "│   ├── \u001b[00m.00000000000000000007.json.crc\u001b[0m\n",
      "│   ├── \u001b[00m.00000000000000000008.json.crc\u001b[0m\n",
      "│   ├── \u001b[00m.00000000000000000009.json.crc\u001b[0m\n",
      "│   ├── \u001b[00m00000000000000000000.json\u001b[0m\n",
      "│   ├── \u001b[00m00000000000000000001.json\u001b[0m\n",
      "│   ├── \u001b[00m00000000000000000002.json\u001b[0m\n",
      "│   ├── \u001b[00m00000000000000000003.json\u001b[0m\n",
      "│   ├── \u001b[00m00000000000000000004.json\u001b[0m\n",
      "│   ├── \u001b[00m00000000000000000005.json\u001b[0m\n",
      "│   ├── \u001b[00m00000000000000000006.json\u001b[0m\n",
      "│   ├── \u001b[00m00000000000000000007.json\u001b[0m\n",
      "│   ├── \u001b[00m00000000000000000008.json\u001b[0m\n",
      "│   └── \u001b[00m00000000000000000009.json\u001b[0m\n",
      "├── \u001b[00mpart-00000-0825fe82-4459-49fb-b69b-4ded01674f63-c000.snappy.parquet\u001b[0m\n",
      "├── \u001b[00mpart-00000-2c886aa1-d13a-4f54-8bd4-0ac291ab5e9a-c000.snappy.parquet\u001b[0m\n",
      "├── \u001b[00mpart-00000-4aa0ba55-e6da-47d5-b256-dcdd2cbcd534-c000.snappy.parquet\u001b[0m\n",
      "├── \u001b[00mpart-00000-65d0b700-60cf-403c-b69f-20a654d1f74f-c000.snappy.parquet\u001b[0m\n",
      "├── \u001b[00mpart-00000-9e9fc6eb-a907-43db-8eda-d7ca94f825b8-c000.snappy.parquet\u001b[0m\n",
      "├── \u001b[00mpart-00000-a5c1f6e4-3317-4a57-8287-af4b12f5e060-c000.snappy.parquet\u001b[0m\n",
      "├── \u001b[00mpart-00000-ae3df0d8-d90d-44af-8f26-7a4f209d5df9-c000.snappy.parquet\u001b[0m\n",
      "├── \u001b[00mpart-00000-bc507886-54ca-4e60-b0ac-6ef0103fee94-c000.snappy.parquet\u001b[0m\n",
      "├── \u001b[00mpart-00000-c71f7f2e-05df-4386-a30a-9a154e2d6005-c000.snappy.parquet\u001b[0m\n",
      "└── \u001b[00mpart-00000-eb12aca8-4707-4b2f-bfdd-1e36d3d7d324-c000.snappy.parquet\u001b[0m\n",
      "\n",
      "2 directories, 40 files\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "tree -a ../../data/security-table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8f830d",
   "metadata": {},
   "source": [
    "### Filter Clauses\n",
    "\n",
    " Suppose we are only interested in the traffic which satisfies the following conditions:\n",
    "\n",
    " - 128.0.0.0 <= `src_ip` <= 191.255.255.255\n",
    " - 1024 <= `src_port` <= 65535\n",
    " - 128.0.0.0 <= `dst_ip` <= 191.255.255.255 and 1024 <= `dst_port` <= 65535"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dc7f1f",
   "metadata": {},
   "source": [
    "### Skipping Effectiveness\n",
    "\n",
    " Now, let's inspect the skipping effectiveness. Your end goal is likely to minimize the total amount of time spent on running these queries and the egress cost, but, for illustration purposes, let’s instead define our cost function as the total number of records scanned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2062522a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128.0.0.0 <= src_ip <= 191.255.255.255:  0.0\n",
      "1024 <= src_port <= 65535:  0.0\n",
      "128.0.0.0 <= dst_ip <= 191.255.255.255 and 1024 <= dst_port <= 65535:  0.0\n"
     ]
    }
   ],
   "source": [
    "from deltalake import DeltaTable\n",
    "import pyarrow.dataset as ds\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "def overlap(a, b):\n",
    "    return a[0] <= b[0] <= a[1] or b[0] <= a[0] <= b[1]\n",
    "\n",
    "dt = DeltaTable('../../data/security-table')\n",
    "\n",
    "lhs = dt.get_add_actions().to_pandas()[['min']].values.tolist()\n",
    "lhs = [x for r in lhs for x in r]\n",
    "lhs = pd.DataFrame.from_dict(lhs)\n",
    "\n",
    "rhs = dt.get_add_actions().to_pandas()[['max']].values.tolist()\n",
    "rhs = [x for r in rhs for x in r]\n",
    "rhs = pd.DataFrame.from_dict(rhs)\n",
    "\n",
    "clause_1, clause_2, clause_3 = 0, 0, 0\n",
    "for (_, min), (_, max) in zip(lhs.iterrows(), rhs.iterrows()):\n",
    "    if overlap(('128.0.0.0', '191.255.255.255'), (min['src_ip'], max['src_ip'])):\n",
    "        clause_1 += 1\n",
    "    if overlap((1024, 65535), (min['src_port'], max['src_port'])):\n",
    "        clause_2 += 1\n",
    "    if overlap(('128.0.0.0', '191.255.255.255'), (min['dst_ip'], max['dst_ip'])) and \\\n",
    "    overlap((1024, 65535), (min['dst_port'], max['dst_port'])):\n",
    "        clause_3 += 1\n",
    "print('128.0.0.0 <= src_ip <= 191.255.255.255: ', 1 - clause_1 / 10)\n",
    "print('1024 <= src_port <= 65535: ', 1 - clause_2 / 10)\n",
    "print('128.0.0.0 <= dst_ip <= 191.255.255.255 and 1024 <= dst_port <= 65535: ', 1 - clause_3 / 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f5b643",
   "metadata": {},
   "source": [
    "### Partition by Range (Explicit Sorting)\n",
    " \n",
    " As our data is randomly generated and so there are no correlations. So let’s try explicitly sorting data before writing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a389edff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/29 02:12:37 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read \\\n",
    "    .format('delta') \\\n",
    "    .load('../../data/security-table')\n",
    "#df.sort('src_ip', 'src_port', 'dst_ip', 'dst_port') \\\n",
    "#    .repartition(10) \\\n",
    "df.repartitionByRange(10, 'src_ip', 'src_port', 'dst_ip') \\\n",
    "    .write \\\n",
    "    .mode('overwrite') \\\n",
    "    .format('delta') \\\n",
    "    .save('../../data/security-table-part-by-range')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1222657",
   "metadata": {},
   "source": [
    "The structure of the table is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44e940f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m../../data/security-table-part-by-range\u001b[0m\n",
      "├── \u001b[00m.part-00000-a3ad6739-b667-46fa-a258-80dacf2be068-c000.snappy.parquet.crc\u001b[0m\n",
      "├── \u001b[00m.part-00001-bd90d54e-0665-46b8-887c-6917bd3ad0bf-c000.snappy.parquet.crc\u001b[0m\n",
      "├── \u001b[00m.part-00002-a9cf4f02-717d-4670-8931-a7ca0ea8b87d-c000.snappy.parquet.crc\u001b[0m\n",
      "├── \u001b[00m.part-00003-e0d7e3f9-06e5-472f-a6e0-3fd6baf32ac8-c000.snappy.parquet.crc\u001b[0m\n",
      "├── \u001b[00m.part-00004-4e8c4634-1c64-4ca8-903e-e39fb64fe825-c000.snappy.parquet.crc\u001b[0m\n",
      "├── \u001b[00m.part-00005-35e20c62-8b06-49c9-be6a-55fb5f1b44fc-c000.snappy.parquet.crc\u001b[0m\n",
      "├── \u001b[00m.part-00006-69d993dc-09e0-4bf9-bab2-a1498d16da2a-c000.snappy.parquet.crc\u001b[0m\n",
      "├── \u001b[00m.part-00007-2174b183-5460-4b35-8704-681d792ec3cc-c000.snappy.parquet.crc\u001b[0m\n",
      "├── \u001b[00m.part-00008-79672ece-f515-4d5e-a5c2-4ab9d6a50dc1-c000.snappy.parquet.crc\u001b[0m\n",
      "├── \u001b[00m.part-00009-d362af9e-5ff8-458f-819c-d2e8e1d90687-c000.snappy.parquet.crc\u001b[0m\n",
      "├── \u001b[01;34m_delta_log\u001b[0m\n",
      "│   ├── \u001b[00m.00000000000000000000.json.crc\u001b[0m\n",
      "│   └── \u001b[00m00000000000000000000.json\u001b[0m\n",
      "├── \u001b[00mpart-00000-a3ad6739-b667-46fa-a258-80dacf2be068-c000.snappy.parquet\u001b[0m\n",
      "├── \u001b[00mpart-00001-bd90d54e-0665-46b8-887c-6917bd3ad0bf-c000.snappy.parquet\u001b[0m\n",
      "├── \u001b[00mpart-00002-a9cf4f02-717d-4670-8931-a7ca0ea8b87d-c000.snappy.parquet\u001b[0m\n",
      "├── \u001b[00mpart-00003-e0d7e3f9-06e5-472f-a6e0-3fd6baf32ac8-c000.snappy.parquet\u001b[0m\n",
      "├── \u001b[00mpart-00004-4e8c4634-1c64-4ca8-903e-e39fb64fe825-c000.snappy.parquet\u001b[0m\n",
      "├── \u001b[00mpart-00005-35e20c62-8b06-49c9-be6a-55fb5f1b44fc-c000.snappy.parquet\u001b[0m\n",
      "├── \u001b[00mpart-00006-69d993dc-09e0-4bf9-bab2-a1498d16da2a-c000.snappy.parquet\u001b[0m\n",
      "├── \u001b[00mpart-00007-2174b183-5460-4b35-8704-681d792ec3cc-c000.snappy.parquet\u001b[0m\n",
      "├── \u001b[00mpart-00008-79672ece-f515-4d5e-a5c2-4ab9d6a50dc1-c000.snappy.parquet\u001b[0m\n",
      "└── \u001b[00mpart-00009-d362af9e-5ff8-458f-819c-d2e8e1d90687-c000.snappy.parquet\u001b[0m\n",
      "\n",
      "2 directories, 22 files\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "tree -a ../../data/security-table-part-by-range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94233446",
   "metadata": {},
   "source": [
    "### Skipping Effectiveness\n",
    "\n",
    " Now, let's inspect the skipping effectiveness. Your end goal is likely to minimize the total amount of time spent on running these queries and the egress cost, but, for illustration purposes, let’s instead define our cost function as the total number of records scanned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f267b6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128.0.0.0 <= src_ip <= 191.255.255.255:  0.6\n",
      "1024 <= src_port <= 65535:  0.0\n",
      "128.0.0.0 <= dst_ip <= 191.255.255.255 and 1024 <= dst_port <= 65535:  0.0\n"
     ]
    }
   ],
   "source": [
    "from deltalake import DeltaTable\n",
    "import pyarrow.dataset as ds\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "def overlap(a, b):\n",
    "    return a[0] <= b[0] <= a[1] or b[0] <= a[0] <= b[1]\n",
    "\n",
    "dt = DeltaTable('../../data/security-table-part-by-range')\n",
    "\n",
    "lhs = dt.get_add_actions().to_pandas()[['min']].values.tolist()\n",
    "lhs = [x for r in lhs for x in r]\n",
    "lhs = pd.DataFrame.from_dict(lhs)\n",
    "\n",
    "rhs = dt.get_add_actions().to_pandas()[['max']].values.tolist()\n",
    "rhs = [x for r in rhs for x in r]\n",
    "rhs = pd.DataFrame.from_dict(rhs)\n",
    "\n",
    "clause_1, clause_2, clause_3 = 0, 0, 0\n",
    "for (_, min), (_, max) in zip(lhs.iterrows(), rhs.iterrows()):\n",
    "    if overlap(('128.0.0.0', '191.255.255.255'), (min['src_ip'], max['src_ip'])):\n",
    "        clause_1 += 1\n",
    "    if overlap((1024, 65535), (min['src_port'], max['src_port'])):\n",
    "        clause_2 += 1\n",
    "    if overlap(('128.0.0.0', '191.255.255.255'), (min['dst_ip'], max['dst_ip'])) and \\\n",
    "    overlap((1024, 65535), (min['dst_port'], max['dst_port'])):\n",
    "        clause_3 += 1\n",
    "print('128.0.0.0 <= src_ip <= 191.255.255.255: ', 1 - clause_1 / 10)\n",
    "print('1024 <= src_port <= 65535: ', 1 - clause_2 / 10)\n",
    "print('128.0.0.0 <= dst_ip <= 191.255.255.255 and 1024 <= dst_port <= 65535: ', 1 - clause_3 / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1382b363",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
